{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/TinArmEngineering/ltc-docs/blob/main/py-client/accessing-artifacts.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    IN_COLAB = True\n",
    "    with open('requirements.txt', 'w') as fout:\n",
    "        fout.write(\"\"\"ltc_client>=0.2.3\n",
    "        pint\n",
    "        pandas\n",
    "        pint-pandas\n",
    "        matplotlib\n",
    "        pyyaml\n",
    "        scipy\n",
    "        openpyxl\"\"\")\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "!pip install -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import ltc_client\n",
    "import logging\n",
    "import time\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import pint_pandas\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting up\n",
    "Log into the website for Tin Arm Engineering's machine solver, and under profile, retrieve your API key, and optionaly, the organisation id that you wish to use.  \n",
    "Do not commit your API key to a repository, and consider it like a password.  There are a few good ways to keep it out of the code base. If I am developing locally I use a configuation file, or environment variable.  If running on Google's [colab](https://colab.research.google.com/) you can use `from google.colab import userdata`. We will want other things cofigured too, so let's use a yaml file for convenience. \n",
    "\n",
    "create a `configurations.yaml` file in this directory with the content.\n",
    "```yaml\n",
    "api_key: 8b6565701741b979645986b3999e0*** # This is your API key, retrieve it from your account page\n",
    "org_id: 664c7a32082dfb8e39e30*** # This is your organization ID, retrieve it from your account page\n",
    "root_url: https://api.ltc.tinarmengineering.com # This is your root URL for the BUILD server, eventually this will be the URL for the Production server\n",
    "queue_url: wss://queue.ltc.tinarmengineering.com:15671/ws # This is the webscoket URL for the RabbitMQ server, again eventually this will be the URL for the Production rabbitMQserver\n",
    "queue_user: t**** #  this is a temporary username for the RabbitMQ server, we will soon have better solution for this\n",
    "queue_password: U*** # this is a temporary password for the RabbitMQ server, we will soon have better solution for this\n",
    "datasheet_path: <path somewhere>/SteelDataSheets/ # This is the path to the Steel Data Sheets, used in some examples\n",
    "results_path: <path somewhere>/Presentations/ # This is the path to where you wan't your results stored.\n",
    "```\n",
    "But of course replace the paths and *** with your keys, and passwords. \n",
    "\n",
    "You can then add that file to your `.gitignore` file by executing ```echo 'configurations.yaml' >> .gitignore```  this will help prevent accitdents.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "!echo 'configurations.yaml' >> .gitignore\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# are we running in google colab?\n",
    "if IN_COLAB:\n",
    "    from google.colab import userdata\n",
    "    \n",
    "    print(\"Running in Google Colab\")\n",
    "    config = {'root_url': \"https://api.ltc.tinarmengineering.com\",\n",
    "              'queue_url':\"wss://queue.ltc.tinarmengineering.com:15671/ws\",\n",
    "              'api_key': userdata.get(\"api_key\"),\n",
    "              'org_id': userdata.get(\"org_id\"),\n",
    "              'queue_user': userdata.get(\"queue_user\"),\n",
    "              'queue_password': userdata.get(\"queue_password\")}\n",
    "else:\n",
    "    \n",
    "    print(\"Running locally\")\n",
    "    with open(\"configurations.yaml\", \"r\") as f:\n",
    "        config = yaml.safe_load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure logging\n",
    "There are many ways to do this, refer to the internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGGING_LEVEL = logging.INFO\n",
    "### Configure Logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(LOGGING_LEVEL)\n",
    "ch = logging.StreamHandler()\n",
    "ch.setLevel(LOGGING_LEVEL)\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "ch.setFormatter(formatter)\n",
    "logger.addHandler(ch)\n",
    "\n",
    "logger.info(f\"tinarm version {ltc_client.__version__}\")\n",
    "logger.info(f\"pint_pandas version {pint_pandas.__version__}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uinit Handling. \n",
    "The API enforces correct units to avoid ambiguity and errors. This is made easy as the API is compatible with [Pint](https://pint.readthedocs.io/en/stable/) and  Pint-Pandas unit handling libraries.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "q = pint_pandas.PintType.ureg\n",
    "q.setup_matplotlib()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the machine. \n",
    "We will do a simulation of a concentrated wound fractional slot machine, we will get on to how to design the machine later.  The machine is comprised of:\n",
    "1. the stator, and a \n",
    "2. rotor, \n",
    "3. and the winding parameters \n",
    "### Stator\n",
    "The tooth wound stator is parameterised by the following dictionary of parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_gap_length = 1 * q.mm\n",
    "\n",
    "stator_parameters = {\n",
    "    \"slot_liner_thickness\": 300 * q.um,\n",
    "    \"stator_bore\": 8.20 * q.cm,\n",
    "    \"tooth_tip_depth\": 1.0 * q.mm,\n",
    "    \"slot_opening\": 1.5 * q.mm,\n",
    "    \"tooth_width\": 9.8 * q.mm,\n",
    "    \"stator_outer_diameter\": 0.136 * q.m,\n",
    "    \"back_iron_thickness\": 5.5 * q.mm,\n",
    "    \"stator_internal_radius\": 500 * q.um,\n",
    "    \"number_slots\": 12 * q.count,\n",
    "    \"tooth_tip_angle\": 70 * q.degrees\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rotor\n",
    "A suitable rotor for this machine is a Surface Mounted rotor with Breadloaf Magnets.  It is parameterised by the following dictionary. We've used the variable `air_gap_length' to link the rotor_od to the stator bore.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotor_parameters = {\n",
    "    \"rotor_od\": stator_parameters[\"stator_bore\"] - 2 * air_gap_length,\n",
    "    \"rotor_bore\": 40 * q.mm,\n",
    "    \"banding_thickness\": 0.5 * q.mm,\n",
    "    \"number_poles\": 10 * q.count,\n",
    "    \"magnet_thickness\": 4.5 * q.millimeter,\n",
    "    \"magnet_pole_arc\": 150 * q.degrees,\n",
    "    \"magnet_inset\": 0.25 * q.millimeter\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Winding\n",
    "The winding is described by the winding parametrs.  These need further explanation.  The parameter symmetry sets the degrees of symmetry used in the simulation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the GCD of the number of slots and the number of poles\n",
    "symmetry = np.gcd(stator_parameters[\"number_slots\"].magnitude, rotor_parameters[\"number_poles\"].magnitude) * q.count\n",
    "symmetry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winding_parameters = {\n",
    "    \"symmetry\": symmetry,\n",
    "    \"number_phases\": 3 * q.count,\n",
    "    \"number_layers\": 2 * q.count,\n",
    "    \"coil_span\": 1 * q.count,\n",
    "    \"turns_per_coil\": 43 * q.count,\n",
    "    \"empty_slots\": 0 * q.count,\n",
    "    \"fill_factor\": 42 * q.percent\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally create the Machine using the class `ltc_client.Machine`. This will initialise it with default materials.  We will change the materials later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_machine = ltc_client.Machine(stator_parameters, rotor_parameters, winding_parameters)\n",
    "\n",
    "for key, value in our_machine.materials.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the simulation job\n",
    "The simulation job is made up of a `Machine`, the opperating points, and the simulation parameters.\n",
    "\n",
    "The Simulation Parameters control the length of the simulation and the number of transient timesteps. To calculate the ironloss we need to simulate over one full electrical period.   We also set the active length here as it is a 2d simulation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_parameters = {\n",
    "       \"samples_per_electrical_period\": 180 * q.count/q.turn,\n",
    "        \"timestep_intervals\": 180 * q.count,\n",
    "        \"active_length\": 65 * q.mm }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operating Point\n",
    "We will set off two simultanious simulation jobs, an open circut simulation with 0 current, and the nominal opperating point with a q axis current density of 6.23 $A/mm^{2}$.  We will have 2 simulation jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op_open_cct = {\n",
    "    \"simulated_speed\": 2060 * q.rpm,\n",
    "    \"q_axis_current_density\": 0 * q.A / q.mm ** 2,\n",
    "    \"d_axis_current_density\": 0 * q.A / q.mm ** 2,\n",
    "    \"current_angle\": 0 * q.degrees\n",
    "    }\n",
    "\n",
    "op_nominal = {\n",
    "    'q_axis_current_density': 6.23 * q.A * q.mm**-2,\n",
    "    \"d_axis_current_density\": 0 * q.A / q.mm ** 2,\n",
    "    'current_angle': 255 * q.degrees,\n",
    "    \"simulated_speed\": 2060 * q.rpm\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "\n",
    "j1_open_cct = ltc_client.Job(our_machine, op_open_cct, simulation_parameters)\n",
    "\n",
    "j2_nominal = ltc_client.Job(our_machine, op_nominal, simulation_parameters)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the API to create and run the simulation job\n",
    "\n",
    "The flow of a job state is :\n",
    "\n",
    "* New: 0,\n",
    "* QueuedForMeshing: 10,\n",
    "* WaitingForMesh: 20,\n",
    "* QueuedForSimSetup: 21,\n",
    "* SimSetup: 22,\n",
    "* QueuedForMeshConversion: 25,\n",
    "* MeshConversion: 26,\n",
    "* QueuedForSolving: 30,\n",
    "* Solving: 40,\n",
    "* QueuedForPostProcess: 50,\n",
    "* PostProcess: 60,\n",
    "* Complete: 70,\n",
    "\n",
    "If a job encouters an error at any point, it is directed to a quarentined state\n",
    "* Quarantined: 80\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Reusable artifacts</b> If the machine geometry is identical to one of your other machines, it will reuse the mesh, so that the results of different operating point simulations are comparable.  This is the case here so  the first job will create the mesh, the 2nd job will wait for the first job to be meshed, and then solve in parrallel.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initalise the api\n",
    "api = ltc_client.Api(config[\"root_url\"], config[\"api_key\"], config[\"org_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the create_job api call. The Swagger documentation for the bare API calls is [here]( \n",
    "https://api.ltc.tinarmengineering.com/docs/index.html#/jobs/post_jobs). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "j1_result = api.create_job(j1_open_cct)\n",
    "j2_result = api.create_job(j2_nominal)\n",
    "\n",
    "print('Job id, {id}, creation_date, {creation_date}, status {status}'.format(**j1_result))\n",
    "print('Job id, {id}, creation_date, {creation_date}, status {status}'.format(**j2_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start a job, we use the api call [`api.update_job_status(job_id, status)`](https://api.ltc.tinarmengineering.com/docs/index.html#/jobs/put_jobs__id__status__status_) and set the job status to `QueuedForMeshing` which is the value 10.  We use the dictionary `JOB_STATUS` as an enum.\n",
    "\n",
    "Once the job is running, we probably want to monitor it.  Later we will show how to use the websockets to get asyncronous job updates without polling, but for this example, we will poll with 10s interval, and wait untill both jobs are in the status\n",
    "`Completed` which has the value 70.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Polling is not good</b> Please don't be tempted to use polling, it is not a good practice.  We will show you how to use websockets to get asyncronous updates in the next example.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ltc_client.api import STATUS_JOB, JOB_STATUS\n",
    "\n",
    "j1_result = api.update_job_status(j1_open_cct.id, JOB_STATUS['QueuedForMeshing'])\n",
    "j2_result = api.update_job_status(j2_nominal.id, JOB_STATUS['QueuedForMeshing'])\n",
    "\n",
    "print('Job id= {id}, creation_date= {creation_date}, status= {status}'.format(**j1_result))\n",
    "print('Job id= {id}, creation_date= {creation_date}, status= {status}'.format(**j2_result))\n",
    "\n",
    "while STATUS_JOB[api.get_job(j1_open_cct.id)['status']] != 'Complete' or STATUS_JOB[api.get_job(j2_nominal.id)['status']] != 'Complete':\n",
    "    print(\"job 1 {0} \\t job 2 {1}\".format(STATUS_JOB[api.get_job(j1_open_cct.id)['status']], STATUS_JOB[api.get_job(j2_nominal.id)['status']] ))\n",
    "    time.sleep(10)\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both the simulations have now completed, (or they are `Quarentiend`, in which case the simple while loop in this example above is not going to terminate!). Assuming they completed, we can now access the results. \n",
    "# Accessing the results\n",
    "\n",
    "## Artifacts\n",
    "The results, configuration files are stored as artifacts against the Job.  Some of the artifacts remain on the solving cluster by default, other artifacts get promoted to an AWS s3 storage instance, and are accessable immediately. \n",
    "The artifacts that havn't been automatically promoted, can be promoted manually, which we will show in a later example. \n",
    "To see the artifacts stored against a job, get the job with the `api.get_job(job_id)` call, and look at the list of artifacts in the returned job. Each artifact has an type, id, and an url. If the url starts with `file://` it has not been promoted, (it is safely stored on the server), if it starts `https://` it is accessable at that url. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j1_result = api.get_job(j1_open_cct.id)\n",
    "for artifact in j1_result['artifacts']:\n",
    "    print(artifact['type'], artifact['url'], artifact['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### RESULT_DATA \n",
    "\n",
    "To get the `RESULT_DATA` file, which is a csv file with the scalar data saved, we can use the Python Data Analytics Library [Pandas](https://pandas.pydata.org/), (or Excell, etc.).  We have take care to put unambigious units into the csv file.  These can be accessed with Pint-Pandas as in the following example\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "j1_result_data = [art for art in j1_result['artifacts'] if art['type']=='RESULT_DATA'][0]\n",
    "j1_df = pd.read_csv(j1_result_data['url'], header=[0, 1], index_col=[0, 1]).pint.quantify(level=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(j1_df['angles'], j1_df['Phase_0'], label='Phase_0')\n",
    "ax.plot(j1_df['angles'], j1_df['Phase_1'], label='Phase_1')\n",
    "ax.plot(j1_df['angles'], j1_df['Phase_2'], label='Phase_2')\n",
    "ax.legend()\n",
    "ax.set_title('Open Circuit back emf at {0:~P}'.format(j1_open_cct.operating_point['simulated_speed']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "In this example we have:\n",
    "1. Created a configuration, either using Google colab secret storage, or a `configuaration.yaml` file.\n",
    "2. Created a `Machine` with a Stator, Rotor, and Winding using correct units\n",
    "3. Created two simulation `Jobs` with a `Machine`, an operating point, and simulation parameters,\n",
    "4. Created the Jobs on the solver, and started them.\n",
    "5. Waited for the simulation to finish,\n",
    "6. Retrieved and plotted the back emf waveform.\n",
    "\n",
    "This covers the very basics of using Tin Arm Engineering's machine solver API. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(j2_nominal.id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
